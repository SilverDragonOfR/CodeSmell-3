{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset/dataclass_metrics.csv')\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed NAN Removal by Median Imputation\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "X[numerical_cols] = imputer.fit_transform(X[numerical_cols])\n",
    "\n",
    "print(\"Performed NAN Removal by Median Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed Scaling using RobustScaler\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "print(\"Performed Scaling using RobustScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before ROSE: Counter({0: 1875, 1: 284})\n",
      "Class distribution after ROSE: Counter({1: 1875, 0: 1875})\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution before ROSE:\", Counter(y))\n",
    "\n",
    "rose = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = rose.fit_resample(X, y)\n",
    "\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_resampled['label'] = y_resampled\n",
    "\n",
    "print(\"Class distribution after ROSE:\", Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 features out of 43 selected by Fisher's Score:\n",
      "['cbo', 'dit', 'rfc', 'lcom', 'tcc', 'lcc', 'totalMethodsQty', 'staticMethodsQty', 'publicMethodsQty', 'privateMethodsQty', 'defaultMethodsQty', 'abstractMethodsQty', 'finalMethodsQty', 'staticFieldsQty', 'publicFieldsQty', 'protectedFieldsQty', 'defaultFieldsQty', 'nosi', 'returnQty', 'loopQty', 'comparisonsQty', 'numbersQty', 'maxNestedBlocksQty', 'lambdasQty', 'logStatementsQty']\n"
     ]
    }
   ],
   "source": [
    "total_features = X_resampled.shape[1]\n",
    "\n",
    "k_fisher = int(0.6 * total_features)\n",
    "selector = SelectKBest(score_func=f_classif, k=k_fisher)\n",
    "X_fisher_selected = selector.fit_transform(X_resampled, y_resampled)\n",
    "\n",
    "fisher_selected_indices = selector.get_support(indices=True)\n",
    "fisher_selected_features = X_resampled.columns[fisher_selected_indices].tolist()\n",
    "\n",
    "print(f\"Top {k_fisher} features out of {total_features} selected by Fisher's Score:\")\n",
    "print(fisher_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 13 Features out of 43 selected after Sequential Forward Selection:\n",
      "['cbo', 'rfc', 'totalMethodsQty', 'staticMethodsQty', 'publicMethodsQty', 'privateMethodsQty', 'finalMethodsQty', 'staticFieldsQty', 'publicFieldsQty', 'nosi', 'loopQty', 'numbersQty', 'lambdasQty']\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled[fisher_selected_features], y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n",
    "\n",
    "sfs = SequentialFeatureSelector(model, k_features='best', forward=True, floating=False, scoring='accuracy', cv=2)\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "final_selected_features = list(sfs.k_feature_names_)\n",
    "final_number_features = len(final_selected_features)\n",
    "\n",
    "print(f\"Final {final_number_features} Features out of {total_features} selected after Sequential Forward Selection:\")\n",
    "print(final_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed Scaling using StandardScaler\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[final_selected_features])\n",
    "X_test_scaled = scaler.transform(X_test[final_selected_features])\n",
    "\n",
    "print(\"Performed Scaling using StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed Feature transformation using PCA\n"
     ]
    }
   ],
   "source": [
    "n_components = len(final_selected_features)  \n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "X_test_pca_df = pd.DataFrame(X_test_pca, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "print(\"Performed Feature transformation using PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction by Random Forest\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(random_state=42, n_estimators=300)\n",
    "\n",
    "final_model.fit(X_train_pca, y_train)\n",
    "y_pred_final = final_model.predict(X_test_pca)\n",
    "\n",
    "print(\"Prediction by Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics with selected features:\n",
      "Accuracy: 0.9760\n",
      "F1-Score: 0.9760\n",
      "Precision: 0.9771\n",
      "Recall: 0.9760\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_final)\n",
    "f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
    "precision = precision_score(y_test, y_pred_final, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_final, average='weighted')\n",
    "\n",
    "print(\"Performance Metrics with selected features:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing pipeline saved as: output/code_smell_preprocessing_pipeline.joblib\n",
      "Trained final model saved as: output/code_smell_detection_model.joblib\n",
      "List of selected features saved as: output/selected_features.joblib\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=len(final_selected_features), random_state=42))\n",
    "])\n",
    "\n",
    "preprocessing_pipeline.fit(X_train[final_selected_features], y_train)\n",
    "\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "pipeline_filename = 'output/code_smell_preprocessing_pipeline.joblib'\n",
    "joblib.dump(preprocessing_pipeline, pipeline_filename)\n",
    "\n",
    "model_filename = 'output/code_smell_detection_model.joblib'\n",
    "joblib.dump(final_model, model_filename)\n",
    "\n",
    "features_filename = 'output/selected_features.joblib'\n",
    "joblib.dump(final_selected_features, features_filename)\n",
    "\n",
    "print(f\"\\nPreprocessing pipeline saved as: {pipeline_filename}\")\n",
    "print(f\"Trained final model saved as: {model_filename}\")\n",
    "print(f\"List of selected features saved as: {features_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
